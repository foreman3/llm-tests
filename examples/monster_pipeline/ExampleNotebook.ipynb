{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm_pipeline.llm_methods import DataFrameProcessor \n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Descriptions\n",
      "Added Danger Descriptions\n",
      "                    name  modified_size  can_fly  good  danger  \\\n",
      "18930  awful holy fairie              2        0     1      -1   \n",
      "\n",
      "                                             description  \\\n",
      "18930  The Awful Holy Fairie, resembling a small, del...   \n",
      "\n",
      "                                      danger_description  \\\n",
      "18930  A harmless, joyful presence that spreads laugh...   \n",
      "\n",
      "                                             environment  \n",
      "18930  Sunny, flower-filled meadow with gentle breeze...  \n"
     ]
    }
   ],
   "source": [
    "# This section generates a description for the record, based on the name and other values of the record.\n",
    "\n",
    "from llm_pipeline.llm_methods import DataFrameProcessor  # Import the new chainable processor\n",
    "\n",
    "# Load test data from CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv('./data/superData.csv')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Select and sample the relevant columns.\n",
    "reduced_df = df[['name', 'modified_size', 'can_fly', 'good', 'danger']]\n",
    "reduced_df = reduced_df.sample(n=1)\n",
    "\n",
    "# Generate a short description of the creature.\n",
    "processed_df = (\n",
    "    DataFrameProcessor(reduced_df)\n",
    "    .llm_call(\n",
    "        prompt_template=\"\"\"The following record is a creature type for a fantasy game. Please provide a description for the creature.\n",
    "The size of the creature is on a scale from very small (0) to extremely large (10). A size of 10 is unbelievably huge—world-threatening in scale.\n",
    "There are ranges for each number: a 1 is very small (from a bug to a fish), a 2 is a small animal (cat, dog, fox, etc.), and 3 is roughly a normal person.\n",
    "A 4 represents a large animal (horse, bear, tiger, lion), while a 5 is a giant animal such as a dragon. Generally, an animal with a larger value would defeat one with a smaller value in combat.\n",
    "Animals may be modified from their nominal state; this modification, reflected in the name, can affect their size or behavior.\n",
    "The can_fly field indicates flight ability (1 for can fly, -1 for cannot, 0 for unspecified). Similarly, the good field indicates moral alignment (1 for good, -1 for evil, 0 for unspecified).\n",
    "The danger field indicates how dangerous the creature is (1 for dangerous, -1 for not dangerous, 0 for unspecified).\n",
    "\n",
    "Please respond with a short, creative description of this creature. Do not include a literal size number (e.g., 'size 2')—instead, be descriptive and creative in your comparisons. Limit your response to 60 words.\n",
    "{record_details}\"\"\",\n",
    "        fields=['name', 'modified_size', 'can_fly', 'good', 'danger'],\n",
    "        output_key=\"description\"\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "print(\"Added Descriptions\")\n",
    "\n",
    "# Generate a short description of the dangerousness of the creature.\n",
    "processed_df = (\n",
    "    DataFrameProcessor(processed_df)\n",
    "    .llm_call(\n",
    "        prompt_template=\"\"\"The following record is a creature type for a fantasy game.\n",
    "The size of the creature is on a scale from very small (0) to extremely large (10). A size of 10 is unbelievably huge—world-threatening in scale.\n",
    "There are ranges for each number: a 1 is very small (from a bug to a fish), a 2 is a small animal (cat, dog, fox, etc.), and 3 is roughly a normal person.\n",
    "A 4 represents a large animal (horse, bear, tiger, lion), while a 5 is a giant animal such as a dragon. Generally, an animal with a larger value would defeat one with a smaller value in combat.\n",
    "Animals may be modified from their nominal state; this modification, reflected in the name, can affect their size or behavior.\n",
    "The can_fly field indicates flight ability (1 for can fly, -1 for cannot, 0 for unspecified). Similarly, the good field indicates moral alignment (1 for good, -1 for evil, 0 for unspecified).\n",
    "The danger field indicates how dangerous the creature is (1 for dangerous, -1 for not dangerous, 0 for unspecified).\n",
    "\n",
    "A description of the animal is also provided. Your task is to provide a creative description of how dangerous the creature is.\n",
    "This should be primarily based on the danger field, but you may also consider the size, flight ability, and moral alignment of the creature.\n",
    "For example, a small, evil creature that can fly might be described as 'small but vicious, and agressive nausence that should be destroyed' while\n",
    " a large, good creature that cannot fly might be described as 'a gentle giant that inokes fear and awe.  It poses no threat, but must be respected'.\n",
    "\n",
    "Please respond with a short, creative description of how dangerous the creature is. Do not include a literal size number, nor the creature's name. Limit your response to 10 words.\n",
    "{record_details}\"\"\",\n",
    "        fields=['name', 'modified_size', 'can_fly', 'good', 'danger', 'description'],\n",
    "        output_key=\"danger_description\"\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "print(\"Added Danger Descriptions\")\n",
    "\n",
    "# Generate a short description of the Environment of the creature.\n",
    "processed_df = (\n",
    "    DataFrameProcessor(processed_df)\n",
    "    .llm_call(\n",
    "        prompt_template=\"\"\"The following record is a creature type for a fantasy game.\n",
    "The size of the creature is on a scale from very small (0) to extremely large (10). A size of 10 is unbelievably huge—world-threatening in scale.\n",
    "There are ranges for each number: a 1 is very small (from a bug to a fish), a 2 is a small animal (cat, dog, fox, etc.), and 3 is roughly a normal person.\n",
    "A 4 represents a large animal (horse, bear, tiger, lion), while a 5 is a giant animal such as a dragon. Generally, an animal with a larger value would defeat one with a smaller value in combat.\n",
    "Animals may be modified from their nominal state; this modification, reflected in the name, can affect their size or behavior.\n",
    "The can_fly field indicates flight ability (1 for can fly, -1 for cannot, 0 for unspecified). Similarly, the good field indicates moral alignment (1 for good, -1 for evil, 0 for unspecified).\n",
    "The danger field indicates how dangerous the creature is (1 for dangerous, -1 for not dangerous, 0 for unspecified).\n",
    "\n",
    "A description of the animal is also provided. Your task is to provide a creative the environment in which the creature is most likely to be found.\n",
    "This should be primarily based on the description and size of the creature, but you may also consider the flight ability, moral alignment, and danger of the creature.\n",
    "For example, a large flying creature should be in an outdoors environment. while an evil creature might be found in a dark, forboding place.\n",
    "\n",
    "Please respond with a short, creative description of the environment in which the creature is found.  Do not include the creature's name or description, focus on the environment.\n",
    "Limit your response to 10 words.\n",
    "{record_details}\"\"\",\n",
    "        fields=['name', 'modified_size', 'can_fly', 'good', 'danger', 'description'],\n",
    "        output_key=\"environment\"\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "#persist the processed data to a CSV file with the generated descriptions\n",
    "# This will allow us save the generated descriptions for later usecd \n",
    "processed_df.to_csv('./data/processed_monsters-x.csv', index=False)\n",
    "\n",
    "print(processed_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed record count: 1000\n"
     ]
    }
   ],
   "source": [
    "# This section adds an Embedding fields each of the generated descriptions to support future kNN searches.\n",
    "# Process the DataFrame to generate embeddings from \"name\" and \"description\"\n",
    "processed_df = (\n",
    "    DataFrameProcessor(processed_df)\n",
    "    .generate_embeddings(\n",
    "        fields=[\"name\", \"description\"],\n",
    "        output_key=\"description_embedding\"  # This is where the embedding will be stored\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "# Add an Embedding field to the DataFrame based on the \"danger_description\" field.\n",
    "processed_df = (   \n",
    "    DataFrameProcessor(processed_df)\n",
    "    .generate_embeddings(\n",
    "        fields=[\"danger_description\"],\n",
    "        output_key=\"danger_embedding\"  # This is where the embedding will be stored\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "# Add an Embedding field to the DataFrame based on the \"environment\" field.\n",
    "processed_df = (\n",
    "    DataFrameProcessor(processed_df)\n",
    "    .generate_embeddings(\n",
    "        fields=[\"environment\"],\n",
    "        output_key=\"environment_embedding\"  # This is where the embedding will be stored\n",
    "    )\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Count the processed records and save the DataFrame.\n",
    "count = len(processed_df)\n",
    "print(f\"Processed record count: {count}\")\n",
    "processed_df.to_pickle('./data/monsters_with_embeddings2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name  \\\n",
      "9020       big ferocious sloth   \n",
      "4497                 big troll   \n",
      "3716             murderous pig   \n",
      "22508  ice-covered giant sloth   \n",
      "\n",
      "                                             description  \n",
      "9020   In the heart of ancient forests dwells the big...  \n",
      "4497   This towering big troll lumbers through the sh...  \n",
      "3716   This hulking beast resembles a monstrous boar,...  \n",
      "22508  The ice-covered giant sloth lumbers through fr...  \n"
     ]
    }
   ],
   "source": [
    "# This section demonstrates finding records related to a string query. \n",
    "# This returns the top matches where the description is similar to the query string.\n",
    "# This is not garuneed to return all matches, but is very fast since it uses the embeddings to find\n",
    "# the top K matches are are most similar to the query string, and then only uses the LLM to rate the top K matches.\n",
    "# This is cheaper and faster than using the LLM to rate all records, and is good for finding SOME matches.\n",
    "\n",
    "# The user provides query string; the processor will prefrom a kNN search based on the query string\n",
    "# Then we perform a double-check by passing the k records to the LLM and asking it to rate the match of the description to the query string\n",
    "# The we apply a filter to the k records to only return good matches\n",
    "# so this is going to return a MAX of K records, but only good matches\n",
    "\n",
    "\n",
    "reloaded_df = pd.read_pickle('./data/monsters_with_embeddings2.pkl')\n",
    "\n",
    "query_str = \"a huge lumbering beast with a thick hide and sharp claws\"\n",
    "\n",
    "# Define a filter function to keep rows with a rating greater than 7.\n",
    "def filter_function(df: pd.DataFrame) -> pd.Series:\n",
    "    return df['knn_rating'].astype(float) > 7\n",
    "\n",
    "# Use the chainable interface:\n",
    "result_df = (\n",
    "    DataFrameProcessor(reloaded_df)\n",
    "    .knn_filter(query=query_str, k=20, embedding_column=\"description_embedding\")\n",
    "    .llm_call(\n",
    "        prompt_template=f\"\"\"The following is a description of a creature type for a fantasy game.\n",
    "Please rate the match of the description to the following statement: {query_str}\n",
    "Rate the match on a scale from 1 to 10, where 1 is a very poor match and 10 is an excellent match.\n",
    "{{record_details}}\"\"\",\n",
    "        fields=[\"description\"],\n",
    "        output_key=\"knn_rating\"\n",
    "    )\n",
    "    .filter(filter_function)  # Chainable filtering step.\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "# Display the top 20 records.\n",
    "print(result_df[['name', 'description']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 15\n",
      "Rows per cluster:\n",
      "environment_cluster_id\n",
      "-1     411\n",
      " 0     233\n",
      " 1     257\n",
      " 2      16\n",
      " 3      32\n",
      " 4       3\n",
      " 5       4\n",
      " 6       5\n",
      " 7       4\n",
      " 8      17\n",
      " 9       3\n",
      " 10      3\n",
      " 11      3\n",
      " 12      3\n",
      " 13      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This section introduces Clusters.clustered_df\n",
    "# First, we generate Cluster IDs using the DBSCAN method, and assign Cluster IDs to each row in the data frame\n",
    "# Note: the clustering paramters eps and min_samples are important to tweak to get good clusters\n",
    "# Also Note: After processing, rows with a cluster id of -1 were not actually clustered\n",
    "# \n",
    "# Clustering gives Groups of related rows based on the proximity of their embeddings in latent space.  \n",
    "# These should have similar meanings. Clusters can be then processed independently.\n",
    "\n",
    "\n",
    "reloaded_df = pd.read_pickle('./data/monsters_with_embeddings2.pkl')\n",
    "\n",
    "clustered_df = (\n",
    "    DataFrameProcessor(reloaded_df)\n",
    "    .cluster_dbscan(embedding_column=\"description_embedding\", output_key=\"description_cluster_id\", eps=0.7, min_samples=3)\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "clustered_df = (\n",
    "    DataFrameProcessor(clustered_df)\n",
    "    .cluster_dbscan(embedding_column=\"danger_embedding\", output_key=\"danger_cluster_id\", eps=0.6, min_samples=3)\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "clustered_df = (\n",
    "    DataFrameProcessor(clustered_df)\n",
    "    .cluster_dbscan(embedding_column=\"environment_embedding\", output_key=\"environment_cluster_id\", eps=0.58, min_samples=3)\n",
    "    .get_df()\n",
    ")\n",
    "\n",
    "# Count the rows in each cluster.\n",
    "cluster_counts = clustered_df['environment_cluster_id'].value_counts().sort_index()\n",
    "\n",
    "# Print the total number of clusters.\n",
    "print(f\"Number of clusters: {len(cluster_counts)}\")\n",
    "\n",
    "# Print the count of rows in each cluster.\n",
    "print(\"Rows per cluster:\")\n",
    "print(cluster_counts)\n",
    "\n",
    "clustered_df.to_pickle('./data/monsters_with_embeddings3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 environment summary: Sunlit glades and meadows filled with vibrant flora.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 1 environment summary: Shadowy forests filled with whispers and hidden dangers.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 2 environment summary: Shadowy, damp alleyways filled with darkness and mystery.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 3 environment summary: Desolate landscapes under dark, stormy skies.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 4 environment summary: Enchanted meadows under picturesque twilight and night skies.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 5 environment summary: Stormy landscapes with cliffs and dark valleys.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 6 environment summary: Tranquil water bodies in lush green settings.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 7 environment summary: Serene vibrant underwater environments rich in marine life.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 8 environment summary: Desolate wastelands shrouded in darkness and despair.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 9 environment summary: Frigid tundra with ice and harsh winds.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 10 environment summary: Vibrant marine life in sunlit coral reefs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 11 environment summary: Shadowy, ancient dungeon environments filled with mystery.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 12 environment summary: Vibrant and whimsical playrooms full of toys and laughter.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cluster 13 environment summary: Mysterious, ominous caves filled with echoes of fear.\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This section demonstrates generating a summary phrase for each cluster.\n",
    "# It will get the cluster IDs, and loop over each cluster, sampling 20 records, and generating a summary phrase for each cluster.\n",
    "# We exclude cluster -1, which is the unclustered records.\n",
    "\n",
    "clustered_df = pd.read_pickle('./data/monsters_with_embeddings3.pkl')\n",
    "\n",
    "# Get all unique clusters, excluding cluster 0.\n",
    "clusters = sorted(clustered_df['environment_cluster_id'].unique())\n",
    "clusters = [c for c in clusters if c != -1]\n",
    "\n",
    "# Loop over each cluster, sample 20 records, and generate a summary phrase.\n",
    "for cluster in clusters:\n",
    "    # Select the records that belong to the current cluster.\n",
    "    cluster_df = clustered_df[clustered_df['environment_cluster_id'] == cluster]\n",
    "    \n",
    "    # Sample up to 20 records (if there are fewer than 20, use them all).\n",
    "    sample_df = cluster_df if len(cluster_df) < 20 else cluster_df.sample(n=20, random_state=42)\n",
    "    \n",
    "    # Define the prompt template for the LLM. The '{record_details}' placeholder\n",
    "    # will be replaced with the combined details of each record (using the selected fields).\n",
    "    prompt_template = (\n",
    "        f\"Below are sample records from cluster {cluster}:\\n\"\n",
    "        \"{record_details}\\n\\n\"\n",
    "        \"Please provide a short summary phrase for this cluster.  Try to limit the response to 10 words or less\"\n",
    "    )\n",
    "    \n",
    "    # Call the LLM with the sample DataFrame.\n",
    "    # In this example, we assume that the 'name' and 'description' fields are desired.\n",
    "    summary = (\n",
    "        DataFrameProcessor(sample_df)\n",
    "        .call_llm_with_dataframe(prompt_template, fields=[\"environment\"])\n",
    "    )\n",
    "    \n",
    "    # Print the cluster number and the generated summary.\n",
    "    print(f\"Cluster {cluster} environment summary: {summary}\\n{'-' * 60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Consolidated Summary:\n",
      "- giant murderous minnow\n",
      "- giant invisible dog\n",
      "- huge microscopy bass\n",
      "- petrified large kraken\n",
      "- lightning dead kraken\n",
      "- enraged weak shark\n",
      "- crazy trout\n",
      "- huge kind leviathan\n",
      "- thunderous leviathan\n",
      "- enormous shadowy leviathan\n",
      "- giant ancient trout\n",
      "- tired ancient leviathan\n",
      "- ancient shadowy shark\n",
      "- aquatic knoble unicorn\n",
      "- aquatic person\n",
      "- Regular Ancient Leviathan\n",
      "- Ice-covered tired shark\n",
      "- Aquatic enraged minotaur\n",
      "- enormous armored minnow\n",
      "- ancient poisonous orc\n",
      "- armored dead mermaid\n",
      "- lightning satanic shark\n",
      "- petrified satanic shark\n",
      "- giant raging fish\n",
      "- earth-bound enormous fish\n",
      "- big ice-covered trout\n",
      "- unholy huge shark\n",
      "- humongous angry leviathan\n"
     ]
    }
   ],
   "source": [
    "# This section demonstrates a large-scale search for records related to a string query, using the batch processing method.\n",
    "# This method passes multiple records to the LLM is a batch, and the consolidates the batches\n",
    "# Its going to be faster and cheaper then processing each record individually,\n",
    "# Additionally, this approach my be good for finding groups of related records if they are in a batch\n",
    "# But, there's still risk that groups may not be detected if they are split across batches\n",
    "\n",
    "# For more exact results, use the exhaustive search method, which processes each record individually.\n",
    "# For faster searches, use the kNN search method or other groupings\n",
    "\n",
    "# This is a nice balance between the two, especially if you can't cluster or group records together.\n",
    "# This will still inlcude all results; it just may not find relationships between records that are split across batches.\n",
    "# And individual records may get supressed during the colidation step.\n",
    "\n",
    "\n",
    "df = pd.read_pickle('./data/monsters_with_embeddings3.pkl')\n",
    "\n",
    "batch_prompt = (\n",
    "    \"Below are a series of records for a fantasy game:\\n\"\n",
    "    \"{record_details}\\n\\n\"\n",
    "    \"Please identify Very Large creatures currently in an underwater enviroment.\\n\"\n",
    "    \"Respond only with the list of creature names.\"\n",
    "\n",
    ")\n",
    "\n",
    "# Use the chainable processor to process in batches and consolidate the results.\n",
    "final_summary = DataFrameProcessor(df).call_llm_in_batches(\n",
    "    prompt_template=batch_prompt,\n",
    "    fields=[\"name\", \"description\", \"danger_description\", \"environment\"],  # adjust fields as needed\n",
    "    batch_size=100,\n",
    "    consolidation_prefix=(\n",
    "        \"The following responses were generated for each batch. \"\n",
    "        \"Please consolidate the list of creature names\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Final Consolidated Summary:\")\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Consolidated Summary:\n",
      "flying fire-breathing priest: flaming breath  \n",
      "evil magical sith: lightsaber  \n",
      "tiny mini jedi: weapon of energy  \n",
      "winged fire-breathing person: blazing breath  \n",
      "angry person: weapon of chaos (emotion)  \n",
      "cursed lightning giant: electric strike  \n",
      "fire-breathing flying priest: flame breath  \n",
      "angry lightning lion: excessive force\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_pickle('./data/monsters_with_embeddings3.pkl')\n",
    "\n",
    "batch_prompt = (\n",
    "    \"Below are a series of records for a fantasy game:\\n\"\n",
    "    \"{record_details}\\n\\n\"\n",
    "    \"I'm looking for flying creatures from the above list that have artificial weapons.\\n\"\n",
    "    \"Meaning, not natural weapons like claws, teeth, horns, etc.  I'm looking for creatures with weapons like swords, guns, etc.\\n\"\n",
    "    \"Please carefully review the above list; and identify flying beings such weapons.\"\n",
    "    \"Think about these creatures, and finally respond with a list in the form of 'Creature Name: Weapon'\"\n",
    ")\n",
    "\n",
    "# Use the chainable processor to process in batches and consolidate the results.\n",
    "final_summary = DataFrameProcessor(df).call_llm_in_batches(\n",
    "    prompt_template=batch_prompt,\n",
    "    fields=[\"name\", \"description\", \"danger_description\", \"environment\"],  # adjust fields as needed\n",
    "    batch_size=500,\n",
    "    consolidation_prefix=(\n",
    "        \"The following responses were generated for each batch. \"\n",
    "        \"Please consolidated the list of creature names and weapons. Produce your response in the form of 'Creature Name: Weapon'\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Final Consolidated Summary:\")\n",
    "print(final_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
